<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Copy Number Detection Using High-thoughput Sequencing</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/serif.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if( window.location.search.match( /print-pdf/gi ) ) {
				var link = document.createElement( 'link' );
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild( link );
			}
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h2>Copy Number Variation Detection Using Next-gen Sequencing</h2>
          <small class="right">Yuling Liu</small>
				</section>

				<section>
					<h2>Copy Number Variation</h2>
            <img src="resource/genetics_CNV.jpg"/>
            <blockquote>
              &ldquo;
                Copy number variation has been associated with cancer, autism,
                schizophrenia, and idiopathic learning disability
              &rdquo;
            </blockquote>
				</section>

        <section>
          <section>
            <h3>Input: Detection Techniques</h3>
            <ul class="left">
                <li>
                  Cytogenetic techniques, e.g. 
                  <a href="#/2/1">Array CGH</a>
                </li>
              
                <li>
                  Virtual karyotyping with 
                  <a href="#/2/2">SNP array</a>
                </li>

                <li>
                  Welcome to the digital world: 
                  <strong>
                    <a href="#/2/3">Next-gen sequencing</a>
                  </strong>
                </li>
            </ul>
          </section>
          <section>
            <h2>ArrayCGH</h2>
            <a href="#/2">
              <img src="resource/arrayCGH_Theisen_FULL.jpg"/>
            </a>
          </section>
          <section>
            <h2>SNP array</h2>
            <a href="#/2">
              <img src="resource/CLL_ForWiki.jpg"/>
            </a>
          </section>
          <section>
            <h2>Next-gen sequencing</h2>
            <a href="#/2">
              <img src="resource/proj106-cnv.jpg"/>
            </a>
          </section>
        </section>

        <section>
          <section>
            <h2>The problem</h2>
            <ul class=left>
              <li>
                Read vector: $R = \{r_1, r_2, \ldots, r_N\}$, $N \sim 10^9$
                # of reads in the library
              </li>
              <li>
                Copy vector: $C = \{c_1, c_2, \ldots, c_K\}$, $K \sim 3\times
                10^9$ length of the genome
              </li>
              <li>
                Model prior: $M_0$, prior belief of the &ldquo;world&rdquo;,
                imposes smoothness of $C$ and includes the knowledge of
                the sequencing process
              </li>
              <li>
                Solve the MAP problem: 
                  $$\arg\max_{M} \sum_C P(C, R \mid M_0, M)$$
              </li>
              <li>
                Denoising problem, $R$ is a 
                <a href="#" class="navigate-down"><strong>noisy</strong> measure</a> 
                of $C$, otherwise $C$ is simply normalized coverage
              </li>
              <li>
                Actual output: break point
              </li>
            </ul>
          </section>
          <section>
            <h2>Noisy Measure<h2>
            <img src="resource/nature09708-f1.2.jpg"/>
          </section>
        </section>

        <section>
          <h3>One Baseline Algorithm: HMM</h3>
          <ul class="left">
            <li>
              Assumption: $P(c_k|c_1, c_2, \ldots, c_{k-1}) = P(c_k|c_{k-1})$
            </li>
            <li>
              Coverage (emission) is a noisy measure of copy number (latent
              variable)
            </li>
            <li>
              $P(c_k = c_{k+1}) >> P(c_k \neq c_{k+1})$, force smoothness
            </li>
            <li>
              Pros: Trivial learning algorithm - EM. 
            <ul>
              <li>
                M: closed form estimator (multinomial)
              </li>
              <li>
                E: VE or BP, exact and runtime in P
              </li>
            </ul>
            </li>
            <li>
              Cons: Naive
              <ul>
                <li>
                  Global parameters, especially $T=P(c_k|c_{k-1})$.
                </li>
                <li>
                  <a href="#/5">
                    <strong>Read $\neq$ Alignment</strong>
                  </a>
                </li>
                <li>
                  <a href="#/9">
                    <strong>Fuzzy break point</strong>
                  </a>
                </li>
                <li>
                  ...
                </li>
              </ul>
            </li>
          <ul>
        </section>

        <section>
          <h2>
            CNVeM: Copy Number Variation Detection Using
            <strong>Uncertainty</strong> of Read
            Mapping
          </h2>
          <small class="right">
            Wang, Z. <i>et al.</i>
          </small>
        </section>

        <section>
          <section>
            <h2>Intuition: Balance</h2>
            <ul class="left">
              <li>
                Use anchor reads to place 
                <a href="#" class="navigate-down">ambiguous reads</a>
              </li>
              <li>Could potentially fix sequencing errors</li>
              <li>Final placement of an ambiguous read is a balance of local
              and contextual &ldquo;happiness&rdquo;</li>
            </ul>
          </section>
          <section>
            <h2>Ambiguous reads</h2>
            <img src="resource/figure1.jpeg"/>
          </section>
        </section>

        <section>
          <section>
            <h2>Formally...</h2>
            <ul class="left">
              <li>
                Solve the MAP problem, the likelihood:
                $$
                  \begin{aligned}
                    P(R \mid \theta, M_0) &amp;=  \sum_{C} P(R, C \mid \theta, M_0) \\
                                          &amp;=  \sum_{C} P(R \mid C, \theta, M_0)
                                                  P(C \mid \theta, M_0)
                  \end{aligned}
                $$
              </li>
              <li>
                Impose sensible smoothness (regularization on model complexity)
                $$
                   P(C \mid \theta, M_0) = P(c_1) \prod_i P(c_i \mid c_{i-1})
                $$
              </li>
              <li>Introduce new latent variables - true mapping for each reads: $Z=\{z_1, z_2,
              \ldots, z_N\}$</li>
              <ul>
                <li>
                  $z_j$ indicates the locations to which $r_j$ could be mapped.
                </li>
              </ul>
            </ul>
          </section>
          <section>
            <ul class="left">
              <li>
                Inovation:
                $$
                  \begin{aligned}
                    P(R \mid C, \theta, M_0) &amp;= \prod_i P(r_i \mid C, \theta, M_0) \\
                                             &amp;= \prod_i \sum_{z_i} 
                                             P(r_i, z_i \mid C, \theta, M_0) \\
                                             &amp;= \prod_i \sum_{z_i} 
                                             P(r_i \mid z_i, C, \theta, M_0)
                                             P(z_i \mid C, \theta, M_0) \\
                                             &amp;= \prod_i \sum_{z_i} 
                                             P(r_i \mid z_i, M_0)
                                             P(z_i \mid C, M_0)

                  \end{aligned}
                $$
              </li>
              <li>
                The simple alignment model $P(r_i \mid z_i, M_0)$: match contributes $1 - \epsilon$ and
                dismatch contributes $\epsilon \mathbin{/} 3$
              </li>
              <li>
                Based on the knowledge of sequencing experiments: 
                $$P(z_i \mid C, M_0) = P(z_i \mid c_i, M_0) \propto c_i$$
              </li>
              <li>
                Learning algorithm is trivial if we look at the structure of the
                MRF in which $P$ factorized...
              </li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Result</h2>
            <ul class="left">
              <li>
                Simulation: no one cares about...
              </li>
              <li>
                Real data: basically it's 
                <a href="#/8/1">good</a>
              </li>
            </ul>
          </section>
          <section>
            <h2>Real Data Result</h2>
            <a href="#/4">
              <img src="resource/em_result.png" />
            </a>
          </section>
        </section>

        <section>
          <h2>
            Dectecting Copy Number Variation with <strong>Mated</strong> Short Reads
          </h2>
          <small class="right">
            Medvedev, P. <i>et al.</i>
          </small>
        </section>

        <section>
          <section>
            <h2>Intuition: Orthogonal Information</h2>
            <ul class="left">
              <li>
                A waste if simply compressing all read info into coverage
              </li>
              <li>
                The reads directly carries the 
                <a href="#/5/1">information</a> 
                of break point
              </li>
              <li>
                However the read info has even more noise (from 
                <a href="#/5/2">HTS</a>
                and alignment), e.g. $175k$ break points in chr1
              </li>
              <li>
                Must find a way to combine coverage and read info
              </li>
            </ul>
          </section>
          <section>
            <h2>Reads & Break Point</h2>
            <a href="#/5">
              <img src="resource/reads_bp.png" />
            </a>
          </section>
          <section>
            <h2>Insertion Size Distribution</h2>
            <a href="#/5">
              <img src="resource/insertion_size.png">
            </a>
          </section>
        </section>

        <section>
          <section>
            <h2>Pipeline</h2>
            <ol class="left">
              <li>Mapping</li>
              <li>
                <a href="#/11/1">Partitioning the reference</a>
              </li>
              <li>
                <a href="#/11/2">Calling potential break points</a>
              </li>
              <li>
                <a href="#/11/1">Building the graph</a>
              </li>
              <li>
                <a href="#/11/3">Solving min-cost flow problem</a>
              </li>
              <li>
                Calling variants and predicting copy counts
              </li>
            </ol>
          </section>

          <section>
            <h2>Donor Graph</h2>
            <a href="#/11">
              <img src="resource/graph_algo.png" />
            </a>
          </section>

          <section>
            <h2>Events</h2>
            <a href="#/11">
              <img src="resource/events.png" />
            </a>
          </section>

          <section>
            <h2>Min-cost Flow Problem Formulation</h2>
            <ul class="left">
              <li>
                <a href="#/11/4">Why min-cost flow?</a>
              </li>
              <li>
                $k_e$ observed coverage, $f_e$ latent coverage (flow).
                $$
                  P(k_e \mid f_e) = 
                  \frac{e^{-\lambda f_e l_e}(\lambda f_e l_e)^{k_e}}{k_e !}
                $$
              </li>
              <li>
                The problem:
                  $$
                    \begin{align}
                      \arg\max_{f} \prod_e P(k_e \mid f_e) &amp;= 
                      \arg\min_{f} \sum_e \lambda_e f_e l_e - 
                      k_e \ln(\lambda_e f_e l_e)
                    \end{align}
                  $$
                  Subject to a set of linear constraint defined by the graph and
                  the property of &ldquo;flow&rdquo;
              </li>
              <li>
                Convex optimization problem and thus in P
              </li>
            </ul>
          </section>

          <section>
            <h2>Why min-cost flow</h2>
            <ul class="left">
              <li>
                The sample genome is a walk in the graph
              </li>
              <li>
                However that's the same as genome assembly
              </li>
              <li>
                Only need the traversal counts
              </li> 
              <li>
                Classical problem could be solved in P, e.g. linear programming
              </li>
            </ul>
          </section>
        </section>

        <section>
          <section>
            <h2>Result</h2>
            <ul class="left">
              <li>
                <a href="#/12/1">
                  Good sensitivity, but worse specificity than Bentley
                  <i>et al.</i>
                </a>
              </li>
              <li>
                The resolution is within tens of bases. 
              </li>
            </ul>
          </section>
          
          <section>
            <h2>Accuracy comparison</h2>
            <img src="resource/precision_tab.png" />
          </section>
        </section>

        <section>
          <h1>Thanks!</h1>
        </section>
			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: 'plugin/math/math.js', async: true }
				]
			});

		</script>

	</body>
</html>
